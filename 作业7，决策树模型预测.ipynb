{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d543cd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练后的决策树预测模型：[[array([1, 1, 1, 1]), 3, [3]], [array([1, 1, 1, 2]), 2, [3, 2, 0]], [array([2, 1, 1, 2]), 2, [3, 2, 0]], [array([3, 1, 1, 2]), 3, [3, 2, 0, 1]], [array([3, 2, 1, 2]), 2, [3, 2, 0, 1]], [array([1, 1, 2, 2]), 1, [3, 2, 1]], [array([1, 2, 2, 2]), 1, [3, 2, 1, 0]], [array([2, 2, 2, 2]), 3, [3, 2, 1, 0]], [array([3, 2, 2, 2]), 3, [3, 2, 1, 0]]]\n",
      "数列里的每个元素记录了分支，每个元素的第三项记录了决策顺序，第一项记录了在该决策顺序下对应的x值，第二项记录了x值对应的预测值\n",
      "\n",
      "输入为原样本特征时的输出结果 [3, 2, 3, 1, 3, 2, 3, 1, 3, 2, 3, 1, 3, 2, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3]\n",
      "\n",
      "随机样本:[[1, 2, 2, 2], [2, 2, 1, 3], [1, 2, 3, 3], [1, 1, 2, 3], [2, 2, 1, 1], [3, 1, 3, 1], [2, 2, 1, 2], [2, 3, 3, 2], [2, 1, 1, 3], [2, 3, 1, 3], [2, 2, 2, 2], [1, 3, 3, 1], [3, 1, 3, 1], [1, 2, 3, 1], [3, 1, 3, 1], [3, 3, 1, 3], [3, 1, 3, 1], [2, 1, 3, 1], [3, 1, 3, 3], [3, 3, 3, 1], [2, 3, 2, 1], [2, 3, 3, 2], [3, 1, 3, 2], [1, 1, 2, 2], [3, 1, 1, 3], [3, 3, 3, 3], [3, 3, 3, 1], [2, 2, 3, 3], [2, 2, 2, 3], [1, 1, 3, 3], [1, 3, 3, 2], [3, 2, 3, 2], [3, 1, 2, 2], [1, 1, 2, 1], [2, 2, 2, 3], [1, 3, 1, 3], [2, 2, 2, 3], [1, 3, 2, 2], [1, 1, 3, 3], [3, 2, 3, 1], [1, 1, 2, 3], [3, 3, 3, 1], [2, 2, 1, 3], [1, 3, 1, 2], [2, 3, 1, 2], [1, 1, 1, 2], [2, 2, 3, 3], [1, 3, 2, 1], [1, 2, 3, 3], [2, 2, 1, 2], [1, 3, 1, 1], [1, 1, 2, 2], [1, 3, 2, 1], [1, 3, 2, 3], [1, 3, 2, 1], [2, 1, 3, 3], [3, 2, 1, 3], [1, 3, 3, 2], [2, 3, 3, 1], [2, 1, 2, 3], [3, 3, 2, 3], [2, 1, 1, 1], [2, 2, 1, 2], [1, 3, 2, 1], [3, 1, 1, 3], [1, 2, 3, 1], [2, 1, 2, 3], [2, 1, 1, 1], [3, 2, 3, 3], [1, 1, 1, 3], [3, 1, 1, 2], [3, 2, 1, 2], [3, 1, 2, 2], [2, 3, 3, 2], [1, 1, 2, 1], [3, 3, 1, 3], [2, 1, 3, 2], [1, 1, 3, 3], [2, 1, 3, 2], [2, 2, 3, 1], [2, 3, 3, 3], [1, 1, 3, 3], [2, 1, 2, 1], [1, 3, 2, 3], [2, 3, 3, 2], [3, 1, 2, 3], [3, 2, 2, 3], [1, 3, 3, 2], [3, 1, 3, 3], [3, 1, 3, 2], [1, 1, 3, 3], [3, 2, 1, 1], [3, 2, 1, 2], [3, 3, 2, 2], [1, 1, 2, 2], [1, 1, 3, 1], [2, 2, 1, 1], [1, 1, 1, 2], [1, 2, 2, 3], [2, 1, 1, 1]]\n",
      "预测值：[1, 2, 3, 1, 3, 3, 2, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 2, 2, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 2, 2, 3, 3, 3, 1, 3, 2, 3, 1, 3, 2, 3, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 2, 3, 1, 3, 3, 2, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import random\n",
    "filepath = 'C:\\\\Users\\\\86136\\\\Desktop\\\\杂物\\\\人工智能与机器学习\\\\作业\\\\作业7\\\\lenses.data'\n",
    "\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    #def __init__(self, n_feature = 1, n_iter = 200, lr = 1e-3, tol = None):\n",
    "        #self.n_feature = n_feature\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    cycle = 0 #记录目前递归次数\n",
    "\n",
    "    i = 0#帮助控制分支长度\n",
    "    processed_model = []\n",
    "    t_type = []\n",
    "\n",
    "\n",
    "    def predict(self,x):    #输入数组x（n*4),预测n个y值作为列表输出\n",
    "        y = []\n",
    "        #print('self.processed_model:',self.processed_model)\n",
    "        for i in x:\n",
    "            y.append(self.predict_one_value(i))\n",
    "        return y\n",
    "\n",
    "\n",
    "    def predict_one_value(self,x):#单个样本预测\n",
    "        y = None\n",
    "        #print(f\"self.processed_model\",self.processed_model)\n",
    "        for i in self.processed_model:\n",
    "            h = 0\n",
    "            while h < len(i[2]):\n",
    "                j = i[2][h]    \n",
    "                h = h+1           \n",
    "                #print(f\"\\n\\ni:{i}\\nx:{x}\\nj:{j}\\nx[j]:{x[j]}\")\n",
    "                if i[0][j] != x[j]:\n",
    "                    #print(f\"\\n\\ni:{i}\\nx:{x}\\nj:{j}\\nx[j]:{x[j]}\\ni[0][j]:{i[0][j]}\")\n",
    "                    break\n",
    "                else:\n",
    "                    y = i[1]\n",
    "                    if h == len(i[2]):\n",
    "                        return i[1]#成功匹配则输出，#同一个x对应多个target，取第一个target作为预测值   \n",
    "        olnm = random.randrange(len(self.t_type))\n",
    "        #print(\"self.t_type:\",self.t_type)\n",
    "        if y != None:#(部分特征值匹配)\n",
    "            return y\n",
    "        return list(self.t_type)[olnm]#无匹配值，随机输出一个预测值\n",
    "    \n",
    "    def model_process(self):#模型简化\n",
    "        #print('self.processed_model:',self.processed_model)\n",
    "        a = 0\n",
    "        while a < len(self.processed_model):\n",
    "            \n",
    "            if len(self.processed_model[a][1]) > 1 :\n",
    "                self.processed_model[a][0] = self.processed_model[a][0][0]#同一个x对应多个target，取拿到的第一个target作为输出\n",
    "            self.processed_model[a][1] = self.processed_model[a][1][0]\n",
    "            #print(f\"\\n\\nself.processed_model:\",self.processed_model)\n",
    "            a = a + 1\n",
    "        #print('\\n\\n处理后self.processed_model:',self.processed_model)\n",
    "    \n",
    "\n",
    "    def train(self,x,t,n):#n为分支最大长度\n",
    "        t = np.array(t)\n",
    "        self.t_type = set()\n",
    "        for i in t:\n",
    "            self.t_type.add(i)\n",
    "        self.processed_model = self.training(x,t,n)\n",
    "        \n",
    "        #print(f\"\\n\\nself.processed_model:\",self.processed_model)\n",
    "        self.model_process()\n",
    "\n",
    "    def training(self,x,t,n):#n为分支最大长度(数据处理，按最大增益顺序)\n",
    "        self.i = 0\n",
    "        a = self.train1(x,t,n)\n",
    "        #print(f\"\\na输出:\",a)\n",
    "        return a\n",
    "    def train1(self,x,t,n):\n",
    "        di_gui = self.one_step_highest_gain(x,t,[])\n",
    "        self.i = self.i + 1\n",
    "        store = []\n",
    "        for h in di_gui:\n",
    "            store.append(h)\n",
    "        if self.i == n:\n",
    "            return store\n",
    "        while self.i < n:\n",
    "            di_gui = []\n",
    "            for h in store:\n",
    "                di_gui.append(h)\n",
    "            store = []\n",
    "            a = 0\n",
    "            for j in di_gui:\n",
    "                # if len(j[0]) == 1:\n",
    "                #     j[0] = j[0][0]#debug去掉多余的括号\n",
    "                st = self.one_step_highest_gain(j[0],j[1],j[2])\n",
    "                for c in st:\n",
    "                    if len(c[0]) == 1:\n",
    "                        c[0] = c[0][0]#debug去掉多余的括号\n",
    "                    #print(f\"c{self.i}{a}:{c}\")\n",
    "                    a = a+1\n",
    "                    store.append(c)\n",
    "            self.i = self.i + 1\n",
    "            #print(f\"\\nstore:\",store)\n",
    "        #print(f\"\\nstore输出:\",store)\n",
    "        return store\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "    x_turn = []#记录x的决策顺序\n",
    "    #计算并返回 最高增益x的位置（第一列是0） 按最高增益x的列排序的并分割后的x和对应的t集：\n",
    "    def one_step_highest_gain(self,x,t,x_turn):#x为多列，t为单列,stop为递归终止次数\n",
    "        self.x_turn = x_turn\n",
    "        #print(\"\\n\\nx:\",x,\"\\n\\n\\nt:\",t)\n",
    "        x = np.array(x)\n",
    "        t = np.array(t)\n",
    "        t_type = set()\n",
    "        for i in t:\n",
    "            t_type.add(i)\n",
    "        \n",
    "        #t_type = list(t_type)\n",
    "        if len(t_type) == 1:# and self.cycle > 1:\n",
    "            self.cycle = self.cycle - 1\n",
    "            abdc = []\n",
    "            for i in self.x_turn:\n",
    "                abdc.append(i)\n",
    "            output = [[x,t,abdc]]\n",
    "            return output\n",
    "    \n",
    "\n",
    "        #最高gain相当于最小的entropy\n",
    "        lowest_entropy = math.inf\n",
    "        lowest_entropy_x_num = 0\n",
    "        if len(x) == len(t):\n",
    "            num = len(x[0])#x的列数（特征维数）\n",
    "        else:\n",
    "            num = 1\n",
    "        a = 0\n",
    "        best_classify = None\n",
    "        while a < num:\n",
    "            #print(\"x:\",x[:,a],\"t:\",t)\n",
    "            outcome = self.compute_entropy_t_when_x(np.array(x)[:,a],t)\n",
    "            #print(f\"entropy{a}:{outcome[0]}\")\n",
    "            #print(f\"outcome{a}:{outcome}\")\n",
    "            if outcome[0] < lowest_entropy:\n",
    "                lowest_entropy_x_num = a\n",
    "                lowest_entropy = outcome[0]\n",
    "                best_classify = outcome\n",
    "\n",
    "            a=a+1\n",
    "        #尝试做一个递归：\n",
    "        #output = [lowest_entropy_x_num]\n",
    "        self.x_turn.append(lowest_entropy_x_num)\n",
    "        output = []\n",
    "        best_classify = best_classify[1:]#去除entropy值\n",
    "        #print(\"\\n\\n\\nbest_classify:\",best_classify)\n",
    "        for i in best_classify:\n",
    "            xo = []\n",
    "            to = []\n",
    "            for j in i:\n",
    "                xo.append(x[j])\n",
    "                to.append(t[j])\n",
    "            \n",
    "            list_x_t = [xo,to]\n",
    "            #print(\"list_x_t:\",list_x_t)\n",
    "            #print(\"output 1:\",output)\n",
    "            abdc = []\n",
    "            for i in self.x_turn:\n",
    "                abdc.append(i)\n",
    "            list_x_t.append(abdc)\n",
    "            output.append(list_x_t)\n",
    "            #print(\"output 2:\",output)\n",
    "        #递归：\n",
    "        self.cycle = self.cycle + 1 \n",
    "        #print(\"\\noutput:\",output)\n",
    "        \n",
    "        #print(\"输出：\",output)\n",
    "        return output\n",
    "        \n",
    "\n",
    "\n",
    "#    def compute_entropy_t_when_x(x,t,x_type_num,t_type_num):\n",
    " #   def compute_entropy_t_when_x(x,t,t_type):\n",
    "    def compute_entropy_t_when_x(self,x,t):#x与t均为单列且长度相同\n",
    "            x = x.flatten()\n",
    "            x_type = set()\n",
    "            t_type = set()\n",
    "            num = len(t)\n",
    "            for i in x:\n",
    "                x_type.add(i)\n",
    "            for i in t:\n",
    "                t_type.add(i)\n",
    "            x_type = list(x_type)\n",
    "            t_type = list(t_type)\n",
    "            #存储x数量各type值对应的数量和相应t的各type数量:\n",
    "            data = list()\n",
    "            i = 0\n",
    "            while i < len(x_type):\n",
    "                x_data = [0]*(1 + len(t_type))#分别存储x某type的数量及对应t各type数量\n",
    "                data.append(x_data)\n",
    "                i = i+1\n",
    "\n",
    "            entropy = 0\n",
    "            output = [entropy]\n",
    "            for i in x_type:\n",
    "                #list_ = [i]\n",
    "                list_ = []\n",
    "                output.append(list_)\n",
    "\n",
    "            b = 0\n",
    "            while b < num:#第b个x\n",
    "                a = 0\n",
    "                while a < len(x_type):#第a类x\n",
    "                    if x[b] == x_type[a]:\n",
    "                        data[a][0] = data[a][0] + 1\n",
    "                        m = 0\n",
    "                        while m < len(t_type):\n",
    "                            if t[b] == t_type[m]:#第b个t为第m类t\n",
    "                                data[a][m+1] = data[a][m+1] + 1 #记录对应t类别的数量\n",
    "                            m = m+1\n",
    "                        \n",
    "                        #记录x的位置\n",
    "                        output[a+1].append(b)\n",
    "\n",
    "\n",
    "                    a = a + 1\n",
    "                b = b+1\n",
    "            #print(data)\n",
    "            #计算entropy：\n",
    "            a = 0\n",
    "            \n",
    "            #print(data)\n",
    "            while a < len(x_type):\n",
    "                entropy_t_when_x_a = 0\n",
    "                b = 1\n",
    "                #print('死循环1')\n",
    "                while b <= len(t_type):\n",
    "                    if data[a][b]/data[a][0] != 0:    \n",
    "                        entropy_t_when_x_a = entropy_t_when_x_a - (data[a][b]/data[a][0])*math.log2(data[a][b]/data[a][0])\n",
    "                    b = b+1\n",
    "                entr = (data[a][0] / num)*entropy_t_when_x_a\n",
    "\n",
    "                #print(\"first: \", entr)\n",
    "\n",
    "\n",
    "                entropy = entropy + entr\n",
    "\n",
    "                #print(\"first: \", entropy)\n",
    "\n",
    "                output[0] = entropy\n",
    "                a=a+1\n",
    "            #print(\"output:\",output)\n",
    "            return output#output为列表，第一个量为entropy，后面若干个量为list（\"\"list的第一位存x的type\"(删掉了），第二位及以后\"(删掉了）存x某个type的所有位置）\n",
    "        \n",
    "\n",
    "\n",
    "lenses = np.loadtxt(filepath,dtype = int,usecols=(1,2,3,4,5))\n",
    "#lenses = lenses[3:20,:]\n",
    "#print(lenses)\n",
    "x = lenses[:,:4]\n",
    "target = lenses[:,4:].flatten()\n",
    "\n",
    "model = DecisionTree()\n",
    "d = 0\n",
    "x_random = []\n",
    "while d < 100:\n",
    "    b = 0\n",
    "    a = []\n",
    "    while b < 4:\n",
    "        b = b+1\n",
    "        a.append(random.randrange(1,4))#随机生成一个样本\n",
    "    x_random.append(a)\n",
    "    d = d+1\n",
    "\n",
    "model.train(x,target,len(x[0]))\n",
    "#predict方法只能预测样本数量大于等于2的情况，样本为1时用predict_one_value方法预测\n",
    "print(f\"\\n训练后的决策树预测模型：{model.processed_model}\\n数列里的每个元素记录了分支，每个元素的第三项记录了决策顺序，第一项记录了在该决策顺序下对应的x值，第二项记录了x值对应的预测值\")\n",
    "print(\"\\n输入为原样本特征时的输出结果\",model.predict(x))\n",
    "y = model.predict(x_random)\n",
    "print(f\"\\n随机样本:{x_random}\\n预测值：{y}\")\n",
    "#number = lenses.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b1f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
